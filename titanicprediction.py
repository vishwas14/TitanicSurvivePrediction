# -*- coding: utf-8 -*-
"""TitanicPrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OC1yBHVcTZbYgnm2f1RFlgqc7jys_xzP

# **Titanic Survive Prediction**
By- Vishwas Anil Kumar

## **Libraries Used**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn.metrics import mean_absolute_error
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression

"""## **About Traning Dataset**"""

col_names = ['PassengerId', 'Survived','Pclass','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked']

training_data = pd.read_csv('train.csv',names = col_names,skiprows = 1)

print(training_data.shape)
training_data.head()

training_data.info()

training_data.dtypes

training_data.isnull().values.any()

training_data[training_data.isnull().any(axis=1)].head()

np.sum(training_data.isnull().any(axis=1))

print("Missing values in Training Set")
print(training_data.isnull().sum())

carrier_count = training_data["Pclass"].value_counts()
sns.set(style="darkgrid")
sns.barplot(carrier_count.index, carrier_count.values, alpha=0.9)
plt.title('Frequency Distribution of pclass')
plt.ylabel('Frequency', fontsize=10)
plt.xlabel('pclass', fontsize=10)
plt.show()

training_data["Pclass"].value_counts().head(10).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()

carrier_count = training_data["Survived"].value_counts()
sns.set(style="darkgrid")
sns.barplot(carrier_count.index, carrier_count.values, alpha=0.9)
plt.title('Frequency Distribution of survived    ')
plt.ylabel('Frequency', fontsize=10)
plt.xlabel('survived    ', fontsize=10)
plt.show()

training_data["Survived"].value_counts().head(10).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()

training_data["Sex"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()

training_data["Age"].value_counts().head(10).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()

training_data["Embarked"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()

training_data.hist(figsize=(15,12),bins = 20, color="g")
plt.title("Features Distribution")
plt.show()

"""## **About Test Dataset**"""

col_names = ['PassengerId', 'Pclass','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked']

test_data = pd.read_csv('test.csv',names = col_names,skiprows = 1)
print(test_data.shape)
test_data.head()

test_data.info()

test_data.dtypes

test_data.isnull().values.any()

test_data[test_data.isnull().any(axis=1)].head()

np.sum(test_data.isnull().any(axis=1))

test_data.isnull().sum()

carrier_count = test_data["Pclass"].value_counts()
sns.set(style="darkgrid")
sns.barplot(carrier_count.index, carrier_count.values, alpha=0.9)
plt.title('Frequency Distribution of pclass')
plt.ylabel('Number of Occurrences', fontsize=12)
plt.xlabel('pclass', fontsize=12)
plt.show()

test_data["Pclass"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()

test_data["Sex"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()

test_data["Age"].value_counts().head(10).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()

test_data["Embarked"].value_counts().head(7).plot(kind = 'pie', autopct='%1.1f%%', figsize=(8, 8)).legend()

test_data.hist(figsize=(15,12),bins = 20, color="g")
plt.title("Features Distribution")
plt.show()

"""## **Co-relation Between features and their dependencies**"""

colormap = plt.cm.RdBu
plt.figure(figsize=(14,12))
plt.title('Pearson Correlation of Features', y=1.05, size=15)
sns.heatmap(training_data.corr(),linewidths=0.1,vmax=1.0, 
            square=True, cmap=colormap, linecolor='white', annot=True)

print("As we can see from the graphs, features has good correlation with Pclass")

training_data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)

print("We can see that the correlation of Sex with survived is more than 0.5 among Sex=female so we are going to add this feature in training")

training_data[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)

print("We can see that the siblling with 1 is high correlated with survival but others are lower and zero")

training_data[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)

print("We can see that the Parch with 1 and 2 is high correlated with survival but others are lower and zero")

g = sns.FacetGrid(training_data, col='Survived')
g.map(plt.hist, 'Age', bins=20)

grid = sns.FacetGrid(training_data, col='Survived', row='Pclass', size=2.2, aspect=1.6)
grid.map(plt.hist, 'Age', alpha=.5, bins=20)
grid.add_legend()

print("Pclass=3 had most passengers, however most did not survive.\nInfant passengers in Pclass=2 and Pclass=3 mostly survived.\nMost passengers in Pclass=1 survived. \nPclass varies in terms of Age distribution of passengers.")

grid = sns.FacetGrid(training_data, row='Embarked', col='Survived', size=2.2, aspect=1.6)
grid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)
grid.add_legend()

print("Higher fare paying passengers had better survival.\nPort of embarkation correlates with survival rates.")

y = training_data["Survived"]

all_data = pd.concat([training_data,test_data],axis=0).reset_index(drop=True)

all_data = all_data.drop(["Survived","PassengerId"],axis=1)

"""## **Missing Values**"""

def missing_value(df):
    number = df.isnull().sum().sort_values(ascending=False)
    number = number[number > 0]
    percentage = df.isnull().sum() *100 / df.shape[0]
    percentage = percentage[percentage > 0].sort_values(ascending=False)
    return  pd.concat([number,percentage],keys=["Total","Percentage"],axis=1)
missing_value(all_data)

## Imputing the missing values with the Mode because mode fill the values with the most accuring values and best for the categorical features
all_data["Cabin"] = all_data["Cabin"].transform(lambda x: x.fillna(x.mode()[0]))

all_data["Embarked"] = all_data["Embarked"].transform(lambda x: x.fillna(x.mode()[0]))

#Mapping the Age into 5 groups from 0 to 4
all_data['Age']=all_data.loc[ all_data['Age'] <= 16, 'Age'] = 0
all_data['Age']=all_data.loc[(all_data['Age'] > 16) & (all_data['Age'] <= 32), 'Age'] = 1
all_data['Age']=all_data.loc[(all_data['Age'] > 32) & (all_data['Age'] <= 48), 'Age'] = 2
all_data['Age']=all_data.loc[(all_data['Age'] > 48) & (all_data['Age'] <= 64), 'Age'] = 3
all_data['Age']=all_data.loc[ all_data['Age'] > 64, 'Age'] = 4

all_data['Fare']=all_data.loc[ all_data['Fare'] <= 7.91, 'Fare'] = 0
all_data['Fare']=all_data.loc[(all_data['Fare'] > 7.91) & (all_data['Fare'] <= 14.454), 'Fare'] = 1
all_data['Fare']=all_data.loc[(all_data['Fare'] > 14.454) & (all_data['Fare'] <= 31), 'Fare']   = 2
all_data['Fare']=all_data.loc[ all_data['Fare'] > 31, 'Fare'] = 3
all_data['Fare']=all_data['Fare'] = all_data['Fare'].astype(int)

missing_value(all_data)

"""## **Splitting of Dataset**"""

all_data = pd.get_dummies(all_data).reset_index(drop=True)

n = len(y)
train_data = all_data[:n]
test_data = all_data[n:]

X = np.array(train_data)
y = np.array(y)

x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=1)

"""## **Model**"""

Rmodel = RandomForestClassifier(random_state=1)
Rmodel.fit(x_train, y_train)
predictions = Rmodel.predict(x_test)
print("Accuracy Score:",Rmodel.score(x_test,y_test))
cross = cross_val_score(Rmodel, x_test, y_test, cv=5)
print("Cross Validation Score:",cross.mean())
print("Mean Absolute Error :",mean_absolute_error(y_test, predictions))

model = LogisticRegression(random_state=1,max_iter=1000)
model.fit(x_train, y_train)
predictions = model.predict(x_test)
print("Accuracy Score:",model.score(x_test,y_test))
cross = cross_val_score(model, x_test, y_test, cv=5)
print("Cross Validation Score:",cross.mean())
print("Mean Absolute Error :",mean_absolute_error(y_test, predictions))

#Test on Decision Tree
model = DecisionTreeClassifier(random_state=1)
model.fit(x_train, y_train)
predictions = model.predict(x_test)
print("Accuracy Score:",model.score(x_test,y_test))
cross = cross_val_score(model, x_test, y_test, cv=5)
print("Cross Validation Score:",cross.mean())
print("Mean Absolute Error :",mean_absolute_error(y_test, predictions))

print("The best model is RandomForest as it has best Cross Validation Score")

Survived = Rmodel.predict(test_data)

Final_Output = pd.read_csv('test.csv',names = col_names,skiprows=1)

Final_Output['Survived'] = Survived
Final_Output

Final_Output.drop(['Pclass','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked'], axis=1)

Final_Output.to_csv('FinalOutput.csv')